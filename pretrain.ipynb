{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12059660,"sourceType":"datasetVersion","datasetId":7590419},{"sourceId":12072209,"sourceType":"datasetVersion","datasetId":7599152}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport random\nfrom collections import defaultdict\n\ninput_txt = '/kaggle/input/keypoint/videoid_label.txt'\nout_train = '/kaggle/working/train.txt'\nout_val = '/kaggle/working/val.txt'\nout_test = '/kaggle/working/test.txt'\n\n#os.makedirs(out_train, exist_ok=True)\n#os.makedirs(out_val, exist_ok=True)\n#os.makedirs(out_test, exist_ok=True)\n# Đọc file và gom theo nhãn\nlabel_dict = defaultdict(list)\nwith open(input_txt, 'r') as f:\n    for line in f:\n        line = line.strip()\n        if not line: continue\n        video_id, label = line.split()\n        label_dict[label].append(video_id)\n\n# Chia tỉ lệ 6:4:4 cho từng nhãn\ntrain_lines, val_lines, test_lines = [], [], []\nfor label, vids in label_dict.items():\n    vids = list(vids)\n    random.shuffle(vids)\n    n = len(vids)\n    n_train = round(n * 0.6)\n    n_val = round(n * 0.2)\n    n_test = n - n_train - n_val\n    train = vids[:n_train]\n    val = vids[n_train:n_train+n_val]\n    test = vids[n_train+n_val:]\n    train_lines.extend([f\"{vid} {label}\\n\" for vid in train])\n    val_lines.extend([f\"{vid} {label}\\n\" for vid in val])\n    test_lines.extend([f\"{vid} {label}\\n\" for vid in test])\n\n# Shuffle lại từng tập để tránh cùng nhãn đứng liền nhau\nrandom.shuffle(train_lines)\nrandom.shuffle(val_lines)\nrandom.shuffle(test_lines)\n\n# Lưu file\nwith open(out_train, 'w') as f: f.writelines(train_lines)\nwith open(out_val, 'w') as f: f.writelines(val_lines)\nwith open(out_test, 'w') as f: f.writelines(test_lines)\n\nprint(\"Đã chia xong. Train:\", len(train_lines), \"Val:\", len(val_lines), \"Test:\", len(test_lines))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-06T08:49:41.144833Z","iopub.execute_input":"2025-06-06T08:49:41.145290Z","iopub.status.idle":"2025-06-06T08:49:41.157278Z","shell.execute_reply.started":"2025-06-06T08:49:41.145266Z","shell.execute_reply":"2025-06-06T08:49:41.156621Z"}},"outputs":[{"name":"stdout","text":"Đã chia xong. Train: 456 Val: 145 Test: 150\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# 1. Pretrain Vision encoder","metadata":{}},{"cell_type":"code","source":"import os\nfrom glob import glob\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nfrom torchvision import transforms\nimport torchvision\nfrom tqdm import tqdm\nimport json","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-06T08:50:27.777707Z","iopub.execute_input":"2025-06-06T08:50:27.778338Z","iopub.status.idle":"2025-06-06T08:50:40.078147Z","shell.execute_reply.started":"2025-06-06T08:50:27.778312Z","shell.execute_reply":"2025-06-06T08:50:40.077607Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def build_label_map(txt_files):\n    labels = set()\n    for txt in txt_files:\n        with open(txt, \"r\") as f:\n            for line in f:\n                parts = line.strip().split()\n                if len(parts) >= 2:\n                    label = ' '.join(parts[1:]).strip()\n                    labels.add(label)\n    labels = sorted(labels)\n    label_map = {lbl: idx for idx, lbl in enumerate(labels)}\n    return label_map","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-06T08:50:40.079152Z","iopub.execute_input":"2025-06-06T08:50:40.079419Z","iopub.status.idle":"2025-06-06T08:50:40.083829Z","shell.execute_reply.started":"2025-06-06T08:50:40.079403Z","shell.execute_reply":"2025-06-06T08:50:40.083294Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"data_root = \"/kaggle/input/image-mask/cropped_hands\"\ntrain_txt = \"/kaggle/working/train.txt\"\nvalid_txt = \"/kaggle/working/val.txt\"\ntest_txt = \"/kaggle/working/test.txt\"\nbatch_size = 32\nnum_workers = 4\nnum_epochs = 6\nlr = 1e-3\nout_ckpt = \"/kaggle/working/pretrained_hand_rgb.pth\"\nout_labelmap = \"/kaggle/working/label_map.json\"\n\nlabel_map = build_label_map([train_txt, valid_txt, test_txt])\nnum_classes = len(label_map)\nprint(\"Số lớp:\", num_classes)\nprint(\"Sample label_map:\", dict(list(label_map.items())[:5]))\n\nwith open(out_labelmap, \"w\") as f:\n    json.dump(label_map, f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-06T08:52:03.188436Z","iopub.execute_input":"2025-06-06T08:52:03.189040Z","iopub.status.idle":"2025-06-06T08:52:03.195311Z","shell.execute_reply.started":"2025-06-06T08:52:03.189008Z","shell.execute_reply":"2025-06-06T08:52:03.194705Z"}},"outputs":[{"name":"stdout","text":"Số lớp: 32\nSample label_map: {'all': 0, 'before': 1, 'black': 2, 'book': 3, 'candy': 4}\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# ==== 2. Dataset for cropped hand images ====\nclass HandImageDataset(Dataset):\n    def __init__(self, data_root, list_file, label_map, transform=None):\n        self.samples = []\n        self.transform = transform\n        with open(list_file, \"r\") as f:\n            for line in f:\n                parts = line.strip().split()\n                if len(parts) == 2:\n                    video_id, label = parts\n                    label_idx = label_map[label]\n                    #img_dir = os.path.join(data_root, video_id)\n                    # All *_left.jpg and *_right.jpg (can add filter for frame sampling if needed)\n                    imgs = sorted(glob(os.path.join(data_root, f\"{video_id}_*_left.jpg\"))) + \\\n                           sorted(glob(os.path.join(data_root, f\"{video_id}_*_right.jpg\")))\n                    for img_path in imgs:\n                        if os.path.isfile(img_path):\n                            self.samples.append((img_path, label_idx))\n    def __len__(self):\n        return len(self.samples)\n    def __getitem__(self, idx):\n        img_path, label = self.samples[idx]\n        img = Image.open(img_path).convert(\"RGB\")\n        if self.transform:\n            img = self.transform(img)\n        return img, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-06T08:54:33.528968Z","iopub.execute_input":"2025-06-06T08:54:33.529224Z","iopub.status.idle":"2025-06-06T08:54:33.535204Z","shell.execute_reply.started":"2025-06-06T08:54:33.529204Z","shell.execute_reply":"2025-06-06T08:54:33.534513Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((112, 112)),\n    transforms.ColorJitter(0.4, 0.4, 0.4, 0.1),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485,0.456,0.406], [0.229,0.224,0.225])\n])\n\ntrain_ds = HandImageDataset(data_root, train_txt, label_map, transform=transform)\nval_ds = HandImageDataset(data_root, valid_txt, label_map, transform=transform)\ntrain_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\nval_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n\nprint(f\"Số ảnh train: {len(train_ds)}, Số ảnh val: {len(val_ds)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-06T08:54:36.358588Z","iopub.execute_input":"2025-06-06T08:54:36.359206Z","iopub.status.idle":"2025-06-06T08:54:53.488107Z","shell.execute_reply.started":"2025-06-06T08:54:36.359177Z","shell.execute_reply":"2025-06-06T08:54:53.487257Z"}},"outputs":[{"name":"stdout","text":"Số ảnh train: 2305, Số ảnh val: 729\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# ==== 3. Vision Model ====\nclass VisionClassifier(nn.Module):\n    def __init__(self, num_classes):\n        super().__init__()\n        backbone = torchvision.models.efficientnet_b0(pretrained=True)\n        self.features = backbone.features\n        self.pool = nn.AdaptiveAvgPool2d(1)\n        self.classifier = nn.Linear(1280, num_classes)\n    def forward(self, x):\n        feat = self.features(x)\n        feat = self.pool(feat).view(x.size(0), -1)\n        return self.classifier(feat)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-06T08:55:10.829768Z","iopub.execute_input":"2025-06-06T08:55:10.830022Z","iopub.status.idle":"2025-06-06T08:55:10.835111Z","shell.execute_reply.started":"2025-06-06T08:55:10.830003Z","shell.execute_reply":"2025-06-06T08:55:10.834448Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel = VisionClassifier(num_classes)\nif torch.cuda.device_count() > 1:\n    print(\"Using DataParallel with {} GPUs\".format(torch.cuda.device_count()))\n    model = nn.DataParallel(model)\nmodel = model.to(device)\noptimizer = optim.AdamW(model.parameters(), lr=lr)\ncriterion = nn.CrossEntropyLoss()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-06T08:55:12.603182Z","iopub.execute_input":"2025-06-06T08:55:12.603858Z","iopub.status.idle":"2025-06-06T08:55:13.388901Z","shell.execute_reply.started":"2025-06-06T08:55:12.603833Z","shell.execute_reply":"2025-06-06T08:55:13.388183Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n100%|██████████| 20.5M/20.5M [00:00<00:00, 138MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Using DataParallel with 2 GPUs\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"best_val_acc = 0\nfor epoch in range(num_epochs):\n    model.train()\n    total_loss, correct, total = 0, 0, 0\n    for imgs, labels in tqdm(train_loader, desc=f\"Train Epoch {epoch+1}\", leave=False):\n        imgs, labels = imgs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n        logits = model(imgs)\n        loss = criterion(logits, labels)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item() * imgs.size(0)\n        preds = logits.argmax(1)\n        correct += (preds == labels).sum().item()\n        total += imgs.size(0)\n    train_acc = correct / total\n    train_loss = total_loss / total\n\n    # Validation\n    model.eval()\n    val_loss, val_correct, val_total = 0, 0, 0\n    with torch.no_grad():\n        for imgs, labels in tqdm(val_loader, desc=\"Valid\", leave=False):\n            imgs, labels = imgs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n            logits = model(imgs)\n            loss = criterion(logits, labels)\n            val_loss += loss.item() * imgs.size(0)\n            preds = logits.argmax(1)\n            val_correct += (preds == labels).sum().item()\n            val_total += imgs.size(0)\n    val_acc = val_correct / val_total\n    val_loss = val_loss / val_total\n\n    print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | \"\n          f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}\")\n\n    # Save best\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        torch.save({\n            \"model\": model.state_dict(),\n            \"label_map\": label_map\n        }, out_ckpt)\n        print(f\"Best model saved at epoch {epoch+1}, val_acc={val_acc:.4f}\")\n\nprint(\"Done. Best val acc:\", best_val_acc)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-06T08:55:25.505358Z","iopub.execute_input":"2025-06-06T08:55:25.505837Z","iopub.status.idle":"2025-06-06T08:56:50.718629Z","shell.execute_reply.started":"2025-06-06T08:55:25.505812Z","shell.execute_reply":"2025-06-06T08:56:50.717851Z"}},"outputs":[{"name":"stderr","text":"                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1/6 | Train Loss: 3.0402 Acc: 0.1831 | Val Loss: 3.2498 Acc: 0.1948\nBest model saved at epoch 1, val_acc=0.1948\n","output_type":"stream"},{"name":"stderr","text":"                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2/6 | Train Loss: 2.3150 Acc: 0.3662 | Val Loss: 3.2723 Acc: 0.1687\n","output_type":"stream"},{"name":"stderr","text":"                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3/6 | Train Loss: 1.8579 Acc: 0.4720 | Val Loss: 3.3247 Acc: 0.2236\nBest model saved at epoch 3, val_acc=0.2236\n","output_type":"stream"},{"name":"stderr","text":"                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4/6 | Train Loss: 1.5030 Acc: 0.5774 | Val Loss: 3.6575 Acc: 0.2140\n","output_type":"stream"},{"name":"stderr","text":"                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5/6 | Train Loss: 1.2124 Acc: 0.6560 | Val Loss: 3.5225 Acc: 0.2757\nBest model saved at epoch 5, val_acc=0.2757\n","output_type":"stream"},{"name":"stderr","text":"                                                              ","output_type":"stream"},{"name":"stdout","text":"Epoch 6/6 | Train Loss: 0.9412 Acc: 0.7293 | Val Loss: 4.1048 Acc: 0.2606\nDone. Best val acc: 0.2757201646090535\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"# 2. pretrain STGCN","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport torch\nfrom torch.utils.data import Dataset\n\nclass PoseSpatialPartDataset(Dataset):\n    def __init__(self, data_root, txt_file, label_map, part='body'):\n        self.samples = []\n        self.label_map = label_map\n        self.part = part\n        with open(txt_file) as f:\n            for line in f:\n                parts = line.strip().split()\n                if len(parts) < 2:\n                    print(f\"WARNING: dòng bị lỗi format: {line}\")\n                    continue\n                npy_id = parts[0]\n                label = ' '.join(parts[1:]).strip()\n                if label not in label_map:\n                    print(f\"WARNING: label '{label}' chưa có trong label_map!\")\n                    continue\n                npy_path = f\"{data_root}/{npy_id}_keypoint.npy\"\n                self.samples.append((npy_path, int(label_map[label])))\n        # Define keypoint slices for each part\n        if part == 'body':\n            self.idx_start, self.idx_end = 0, 25\n        elif part == 'left':\n            self.idx_start, self.idx_end = 25, 46\n        elif part == 'right':\n            self.idx_start, self.idx_end = 46, 67\n        else:\n            raise ValueError(\"Unknown part: \" + part)\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        npy_path, label = self.samples[idx]\n        keypoints = np.load(npy_path)  # (T, 67, 3) expected\n        # Auto fix shape if needed\n        if keypoints.shape[-2:] == (67, 3):\n            pass\n        elif keypoints.shape[0] == 67 and keypoints.shape[1] == 3:\n            keypoints = np.transpose(keypoints, (2, 0, 1))\n        elif keypoints.shape[1] == 3 and keypoints.shape[2] == 67:\n            keypoints = np.transpose(keypoints, (0, 2, 1))\n        else:\n            raise RuntimeError(f\"Unrecognized keypoints shape: {keypoints.shape}\")\n        part_kp = keypoints[:, self.idx_start:self.idx_end, :]  # (T, N, 3)\n        if idx == 0:\n            print(f\"Dataset part_kp.shape: {part_kp.shape}\")\n        return torch.tensor(part_kp, dtype=torch.float32), label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-06T08:59:10.248636Z","iopub.execute_input":"2025-06-06T08:59:10.249205Z","iopub.status.idle":"2025-06-06T08:59:10.257656Z","shell.execute_reply.started":"2025-06-06T08:59:10.249185Z","shell.execute_reply":"2025-06-06T08:59:10.257074Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"class SpatialGCNLayer(nn.Module):\n    def __init__(self, in_channels, out_channels, A):\n        super().__init__()\n        self.register_buffer('A', A)\n        self.fc = nn.Linear(in_channels, out_channels)\n        self.bn = nn.BatchNorm1d(out_channels)\n\n    def forward(self, x):  # x: (B, N, in_channels)\n        h = self.fc(x)  # (B, N, out_channels)\n        h = h.permute(0, 2, 1)  # (B, out_channels, N)\n        h = torch.matmul(h, self.A)  # (B, out_channels, N)\n        h = self.bn(h)  # BatchNorm trên out_channels\n        h = h.permute(0, 2, 1)  # (B, N, out_channels)\n        return torch.relu(h)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-06T08:59:19.654195Z","iopub.execute_input":"2025-06-06T08:59:19.654709Z","iopub.status.idle":"2025-06-06T08:59:19.659548Z","shell.execute_reply.started":"2025-06-06T08:59:19.654683Z","shell.execute_reply":"2025-06-06T08:59:19.659006Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"class SpatialPoseEncoder(nn.Module):\n    def __init__(self, in_channels, num_joints, num_classes, A, hid_dim=128, out_dim=256):\n        super().__init__()\n        self.gcn1 = SpatialGCNLayer(in_channels, hid_dim, A)\n        self.gcn2 = SpatialGCNLayer(hid_dim, out_dim, A)\n        self.classifier = nn.Linear(out_dim * num_joints, num_classes)\n\n    def forward(self, x):  # x: (B, T, N, 3)\n        #print(\"Encoder x.shape:\", x.shape)\n        B, T, N, C = x.shape\n        assert N == self.gcn1.A.shape[0], f\"x.shape={x.shape}, A.shape={self.gcn1.A.shape}\"\n        x = x.view(B * T, N, C)  # (B*T, N, 3)\n        h = self.gcn1(x)         # (B*T, N, hid_dim)\n        h = self.gcn2(h)         # (B*T, N, out_dim)\n        h = h.view(B, T, N, -1)  # (B, T, N, out_dim)\n        h = h.mean(1)            # (B, N, out_dim)\n        h = h.permute(0, 2, 1)   # (B, out_dim, N)\n        logits = self.classifier(h.flatten(1))  # (B, num_classes)\n        return logits, h","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-06T08:59:44.215677Z","iopub.execute_input":"2025-06-06T08:59:44.216431Z","iopub.status.idle":"2025-06-06T08:59:44.222514Z","shell.execute_reply.started":"2025-06-06T08:59:44.216404Z","shell.execute_reply":"2025-06-06T08:59:44.221772Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def gather_special_frames(pose_feat, mask_indices):\n    \"\"\"\n    pose_feat: (B, C, N, T)\n    mask_indices: list of [tensor(F_b,), ...]  # F_b: số frame của mỗi sample cần fusion\n    Return: list of (B, C, N, F_b)\n    \"\"\"\n    outputs = []\n    for b, idxs in enumerate(mask_indices):\n        # idxs: (F_b,), pose_feat[b]: (C, N, T)\n        sel = pose_feat[b, :, :, idxs]  # (C, N, F_b)\n        outputs.append(sel)\n    return outputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-06T08:59:56.871361Z","iopub.execute_input":"2025-06-06T08:59:56.871915Z","iopub.status.idle":"2025-06-06T08:59:56.875719Z","shell.execute_reply.started":"2025-06-06T08:59:56.871892Z","shell.execute_reply":"2025-06-06T08:59:56.875152Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"def get_spatial_adjacency(num_node, edge):\n    A = np.zeros((num_node, num_node))\n    for i, j in edge:\n        A[i, j] = 1\n        A[j, i] = 1\n    # Normalize\n    Dl = np.sum(A, 0)\n    Dn = np.zeros((num_node, num_node))\n    for i in range(num_node):\n        if Dl[i] > 0:\n            Dn[i, i] = Dl[i] ** (-1)\n    A_normalized = np.dot(A, Dn)\n    return torch.tensor(A_normalized, dtype=torch.float32)\n\ndef get_body_spatial_graph():\n    # 25 body keypoints (Mediapipe hoặc OpenPose định nghĩa)\n    num_node = 25\n    self_link = [(i, i) for i in range(num_node)]\n    neighbor_link = [\n        (0, 1), (1, 2), (2, 3), (3, 7),\n        (0, 4), (4, 5), (5, 6), (6, 8),\n        (9, 10), (11, 12), (11, 13), (13, 15), (15, 21), (15, 19), (15, 17),\n        (17, 19), (11, 23), (12, 14), (14, 16), (16, 18), (16, 20), (16, 22),\n        (18, 20), (12, 24), (23, 24)\n    ]\n    edge = self_link + neighbor_link\n    return get_spatial_adjacency(num_node, edge)\n\ndef get_left_hand_spatial_graph():\n    # 21 left hand keypoints (Mediapipe)\n    num_node = 21\n    self_link = [(i, i) for i in range(num_node)]\n    neighbor_link = [\n        (0, 1),(1, 2),(2, 3),(3, 4),\n        (0, 5),(5, 6),(6, 7),(7, 8),\n        (0, 9),(9, 10),(10, 11),(11, 12),\n        (0, 13),(13, 14),(14, 15),(15, 16),\n        (0, 17),(17, 18),(18, 19),(19, 20)\n    ]\n    edge = self_link + neighbor_link\n    return get_spatial_adjacency(num_node, edge)\ndef get_right_hand_spatial_graph():\n    # 21 right hand keypoints (Mediapipe)\n    num_node = 21\n    self_link = [(i, i) for i in range(num_node)]\n    neighbor_link = [\n        (0, 1),(1, 2),(2, 3),(3, 4),\n        (0, 5),(5, 6),(6, 7),(7, 8),\n        (0, 9),(9, 10),(10, 11),(11, 12),\n        (0, 13),(13, 14),(14, 15),(15, 16),\n        (0, 17),(17, 18),(18, 19),(19, 20)\n    ]\n    edge = self_link + neighbor_link\n    return get_spatial_adjacency(num_node, edge)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-06T09:00:58.352104Z","iopub.execute_input":"2025-06-06T09:00:58.352497Z","iopub.status.idle":"2025-06-06T09:00:58.370180Z","shell.execute_reply.started":"2025-06-06T09:00:58.352465Z","shell.execute_reply":"2025-06-06T09:00:58.369321Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"PART_INFO = {\n    'body':  (0, 25),\n    'left':  (25, 46),\n    'right': (46, 67)\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-06T09:01:09.344944Z","iopub.execute_input":"2025-06-06T09:01:09.345507Z","iopub.status.idle":"2025-06-06T09:01:09.349078Z","shell.execute_reply.started":"2025-06-06T09:01:09.345484Z","shell.execute_reply":"2025-06-06T09:01:09.348396Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nimport torch.optim as optim\nimport torch.nn as nn\n\ndef train_pose_spatial_part(part, num_joints, get_A_func, best_ckpt_file):\n    print(f\"\\n--- Pretraining {part} ---\")\n    train_ds = PoseSpatialPartDataset(data_root, train_txt, label_map, part=part)\n    val_ds = PoseSpatialPartDataset(data_root, val_txt, label_map, part=part)\n    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n    print(f\"Số mẫu train: {len(train_ds)}, val: {len(val_ds)}\")\n    print(f\"Số batch train: {len(train_loader)}, val: {len(val_loader)}\")\n\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    A = get_A_func().to(device)\n    model = SpatialPoseEncoder(in_channels=3, num_joints=num_joints, num_classes=num_classes, A=A)\n    if torch.cuda.device_count() > 1:\n        print(\"Using DataParallel with {} GPUs\".format(torch.cuda.device_count()))\n        model = nn.DataParallel(model)\n    model = model.to(device)\n    optimizer = optim.AdamW(model.parameters(), lr=lr)\n    criterion = nn.CrossEntropyLoss()\n    best_val_acc = 0\n    \n    for epoch in range(num_epochs):\n        model.train()\n        total_loss, correct, total = 0, 0, 0\n        for x, labels in tqdm(train_loader, desc=f\"Train {part} Epoch {epoch+1}\", leave=False):\n            #print(\"Batch x.shape:\", x.shape)\n            x, labels = x.to(device), labels.to(device)\n            logits, _ = model(x)\n            loss = criterion(logits, labels)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item() * x.size(0)\n            preds = logits.argmax(1)\n            correct += (preds == labels).sum().item()\n            total += x.size(0)\n        if total > 0:\n            train_acc = correct / total\n            train_loss = total_loss / total\n        else:\n            train_acc = 0\n            train_loss = 0\n            print(\"WARNING: Không có sample nào trong batch train!\")\n        \n        model.eval()\n        val_loss, val_correct, val_total = 0, 0, 0\n        with torch.no_grad():\n            for x, labels in tqdm(val_loader, desc=f\"Val {part} Epoch {epoch+1}\", leave=False):\n                x, labels = x.to(device), labels.to(device)\n                logits, _ = model(x)\n                loss = criterion(logits, labels)\n                val_loss += loss.item() * x.size(0)\n                preds = logits.argmax(1)\n                val_correct += (preds == labels).sum().item()\n                val_total += x.size(0)\n        if val_total > 0:\n            val_acc = val_correct / val_total\n            val_loss = val_loss / val_total\n        else:\n            val_acc = 0\n            val_loss = 0\n            print(\"WARNING: Không có sample nào trong batch val!\")\n\n        print(f\"[{part}] Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | \"\n              f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}\")\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            torch.save({\"model\": model.state_dict(), \"label_map\": label_map}, best_ckpt_file)\n            print(f\"Best model saved at epoch {epoch+1}, val_acc={val_acc:.4f}\")\n\n    print(f\"Done {part}. Best val acc: {best_val_acc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-06T09:03:00.166996Z","iopub.execute_input":"2025-06-06T09:03:00.167548Z","iopub.status.idle":"2025-06-06T09:03:00.179034Z","shell.execute_reply.started":"2025-06-06T09:03:00.167527Z","shell.execute_reply":"2025-06-06T09:03:00.178368Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"data_root = \"/kaggle/input/keypoint/keypoints\"\ntrain_txt = \"/kaggle/working/train.txt\"\nval_txt = \"/kaggle/working/val.txt\"\ntest_txt = \"/kaggle/working/test.txt\"\nbatch_size = 32\nnum_workers = 4\nnum_epochs = 10\nlr = 1e-3\n\nlabel_map = build_label_map([train_txt, val_txt, test_txt])\nnum_classes = len(label_map)\nwith open(\"label_map_pose.json\", \"w\") as f:\n    json.dump(label_map, f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-06T09:05:54.853819Z","iopub.execute_input":"2025-06-06T09:05:54.854314Z","iopub.status.idle":"2025-06-06T09:05:54.859945Z","shell.execute_reply.started":"2025-06-06T09:05:54.854287Z","shell.execute_reply":"2025-06-06T09:05:54.859271Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"print(get_body_spatial_graph().shape)       # (25, 25)\nprint(get_left_hand_spatial_graph().shape)  # (21, 21)\nprint(get_right_hand_spatial_graph().shape) # (21, 21)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-06T09:06:05.030949Z","iopub.execute_input":"2025-06-06T09:06:05.031474Z","iopub.status.idle":"2025-06-06T09:06:05.102302Z","shell.execute_reply.started":"2025-06-06T09:06:05.031451Z","shell.execute_reply":"2025-06-06T09:06:05.101604Z"}},"outputs":[{"name":"stdout","text":"torch.Size([25, 25])\ntorch.Size([21, 21])\ntorch.Size([21, 21])\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"train_pose_spatial_part('body',  num_joints=25, get_A_func=get_body_spatial_graph, best_ckpt_file=\"/kaggle/working/spatial_body_best.pth\")\ntrain_pose_spatial_part('left',  num_joints=21, get_A_func=get_left_hand_spatial_graph, best_ckpt_file=\"/kaggle/working/spatial_left_best.pth\")\ntrain_pose_spatial_part('right', num_joints=21, get_A_func=get_right_hand_spatial_graph, best_ckpt_file=\"/kaggle/working/spatial_right_best.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-06T09:06:21.127345Z","iopub.execute_input":"2025-06-06T09:06:21.127839Z","iopub.status.idle":"2025-06-06T09:06:41.387955Z","shell.execute_reply.started":"2025-06-06T09:06:21.127815Z","shell.execute_reply":"2025-06-06T09:06:41.386930Z"}},"outputs":[{"name":"stdout","text":"\n--- Pretraining body ---\nSố mẫu train: 456, val: 145\nSố batch train: 15, val: 5\nUsing DataParallel with 2 GPUs\n","output_type":"stream"},{"name":"stderr","text":"Train body Epoch 1:   0%|          | 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:180.)\n  return F.linear(input, self.weight, self.bias)\nTrain body Epoch 1:  40%|████      | 6/15 [00:00<00:00,  9.88it/s]","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 25, 3)\n","output_type":"stream"},{"name":"stderr","text":"Val body Epoch 1:   0%|          | 0/5 [00:00<?, ?it/s]            ","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 25, 3)\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"[body] Epoch 1/10 | Train Loss: 4.4749 Acc: 0.0482 | Val Loss: 3.3951 Acc: 0.0690\nBest model saved at epoch 1, val_acc=0.0690\n","output_type":"stream"},{"name":"stderr","text":"Train body Epoch 2:   0%|          | 0/15 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 25, 3)\n","output_type":"stream"},{"name":"stderr","text":"Val body Epoch 2:   0%|          | 0/5 [00:00<?, ?it/s]           ","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 25, 3)\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"[body] Epoch 2/10 | Train Loss: 3.3263 Acc: 0.1535 | Val Loss: 3.4384 Acc: 0.0966\nBest model saved at epoch 2, val_acc=0.0966\n","output_type":"stream"},{"name":"stderr","text":"Train body Epoch 3:  60%|██████    | 9/15 [00:00<00:00, 34.18it/s]","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 25, 3)\n","output_type":"stream"},{"name":"stderr","text":"Val body Epoch 3:   0%|          | 0/5 [00:00<?, ?it/s]           ","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 25, 3)\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"[body] Epoch 3/10 | Train Loss: 3.0046 Acc: 0.1645 | Val Loss: 3.4457 Acc: 0.0828\n","output_type":"stream"},{"name":"stderr","text":"Train body Epoch 4:   7%|▋         | 1/15 [00:00<00:02,  6.01it/s]","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 25, 3)\n","output_type":"stream"},{"name":"stderr","text":"Val body Epoch 4:   0%|          | 0/5 [00:00<?, ?it/s]           ","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 25, 3)\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"[body] Epoch 4/10 | Train Loss: 2.7524 Acc: 0.2215 | Val Loss: 3.1755 Acc: 0.1241\nBest model saved at epoch 4, val_acc=0.1241\n","output_type":"stream"},{"name":"stderr","text":"Train body Epoch 5:   7%|▋         | 1/15 [00:00<00:02,  5.66it/s]","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 25, 3)\n","output_type":"stream"},{"name":"stderr","text":"Val body Epoch 5:   0%|          | 0/5 [00:00<?, ?it/s]           ","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 25, 3)\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"[body] Epoch 5/10 | Train Loss: 2.6069 Acc: 0.2478 | Val Loss: 3.0355 Acc: 0.1931\nBest model saved at epoch 5, val_acc=0.1931\n","output_type":"stream"},{"name":"stderr","text":"Train body Epoch 6:   7%|▋         | 1/15 [00:00<00:02,  5.91it/s]","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 25, 3)\n","output_type":"stream"},{"name":"stderr","text":"Val body Epoch 6:   0%|          | 0/5 [00:00<?, ?it/s]           ","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 25, 3)\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"[body] Epoch 6/10 | Train Loss: 2.3707 Acc: 0.2763 | Val Loss: 3.0938 Acc: 0.1862\n","output_type":"stream"},{"name":"stderr","text":"Train body Epoch 7:   0%|          | 0/15 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 25, 3)\n","output_type":"stream"},{"name":"stderr","text":"Val body Epoch 7:   0%|          | 0/5 [00:00<?, ?it/s]           ","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 25, 3)\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"[body] Epoch 7/10 | Train Loss: 2.2551 Acc: 0.3202 | Val Loss: 3.1144 Acc: 0.1724\n","output_type":"stream"},{"name":"stderr","text":"Train body Epoch 8:   0%|          | 0/15 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 25, 3)\n","output_type":"stream"},{"name":"stderr","text":"Val body Epoch 8:   0%|          | 0/5 [00:00<?, ?it/s]           ","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 25, 3)\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"[body] Epoch 8/10 | Train Loss: 2.2885 Acc: 0.3180 | Val Loss: 3.1482 Acc: 0.1793\n","output_type":"stream"},{"name":"stderr","text":"Train body Epoch 9:   7%|▋         | 1/15 [00:00<00:02,  6.28it/s]","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 25, 3)\n","output_type":"stream"},{"name":"stderr","text":"Val body Epoch 9:   0%|          | 0/5 [00:00<?, ?it/s]           ","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 25, 3)\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"[body] Epoch 9/10 | Train Loss: 2.1977 Acc: 0.3333 | Val Loss: 3.1713 Acc: 0.2138\nBest model saved at epoch 9, val_acc=0.2138\n","output_type":"stream"},{"name":"stderr","text":"Train body Epoch 10:   0%|          | 0/15 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 25, 3)\n","output_type":"stream"},{"name":"stderr","text":"Val body Epoch 10:   0%|          | 0/5 [00:00<?, ?it/s]           ","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 25, 3)\n","output_type":"stream"},{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"[body] Epoch 10/10 | Train Loss: 2.0976 Acc: 0.3333 | Val Loss: 2.9866 Acc: 0.2345\nBest model saved at epoch 10, val_acc=0.2345\nDone body. Best val acc: 0.2345\n\n--- Pretraining left ---\nSố mẫu train: 456, val: 145\nSố batch train: 15, val: 5\nUsing DataParallel with 2 GPUs\n","output_type":"stream"},{"name":"stderr","text":"Train left Epoch 1:   7%|▋         | 1/15 [00:00<00:02,  5.94it/s]","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 21, 3)\n","output_type":"stream"},{"name":"stderr","text":"Val left Epoch 1:   0%|          | 0/5 [00:00<?, ?it/s]            ","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 21, 3)\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"[left] Epoch 1/10 | Train Loss: 3.9497 Acc: 0.0658 | Val Loss: 3.3844 Acc: 0.0759\nBest model saved at epoch 1, val_acc=0.0759\n","output_type":"stream"},{"name":"stderr","text":"Train left Epoch 2:   0%|          | 0/15 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 21, 3)\n","output_type":"stream"},{"name":"stderr","text":"Val left Epoch 2:   0%|          | 0/5 [00:00<?, ?it/s]           ","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 21, 3)\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"[left] Epoch 2/10 | Train Loss: 3.2880 Acc: 0.1316 | Val Loss: 3.3171 Acc: 0.0759\n","output_type":"stream"},{"name":"stderr","text":"Train left Epoch 3:  53%|█████▎    | 8/15 [00:00<00:00, 36.04it/s]","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 21, 3)\n","output_type":"stream"},{"name":"stderr","text":"Val left Epoch 3:   0%|          | 0/5 [00:00<?, ?it/s]           ","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 21, 3)\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"[left] Epoch 3/10 | Train Loss: 3.1386 Acc: 0.1162 | Val Loss: 3.3551 Acc: 0.0897\nBest model saved at epoch 3, val_acc=0.0897\n","output_type":"stream"},{"name":"stderr","text":"Train left Epoch 4:   0%|          | 0/15 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 21, 3)\n","output_type":"stream"},{"name":"stderr","text":"Val left Epoch 4:   0%|          | 0/5 [00:00<?, ?it/s]           ","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 21, 3)\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"[left] Epoch 4/10 | Train Loss: 3.0724 Acc: 0.1469 | Val Loss: 3.3598 Acc: 0.1655\nBest model saved at epoch 4, val_acc=0.1655\n","output_type":"stream"},{"name":"stderr","text":"Train left Epoch 5:  53%|█████▎    | 8/15 [00:00<00:00, 35.79it/s]","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 21, 3)\n","output_type":"stream"},{"name":"stderr","text":"Val left Epoch 5:   0%|          | 0/5 [00:00<?, ?it/s]            ","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 21, 3)\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"[left] Epoch 5/10 | Train Loss: 2.8416 Acc: 0.1930 | Val Loss: 3.1203 Acc: 0.1724\nBest model saved at epoch 5, val_acc=0.1724\n","output_type":"stream"},{"name":"stderr","text":"Train left Epoch 6:   0%|          | 0/15 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 21, 3)\n","output_type":"stream"},{"name":"stderr","text":"Val left Epoch 6:   0%|          | 0/5 [00:00<?, ?it/s]            ","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 21, 3)\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"[left] Epoch 6/10 | Train Loss: 2.8156 Acc: 0.1820 | Val Loss: 3.3003 Acc: 0.2069\nBest model saved at epoch 6, val_acc=0.2069\n","output_type":"stream"},{"name":"stderr","text":"Train left Epoch 7:   7%|▋         | 1/15 [00:00<00:02,  6.00it/s]","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 21, 3)\n","output_type":"stream"},{"name":"stderr","text":"Val left Epoch 7:   0%|          | 0/5 [00:00<?, ?it/s]           ","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 21, 3)\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"[left] Epoch 7/10 | Train Loss: 2.7344 Acc: 0.2346 | Val Loss: 3.1155 Acc: 0.1310\n","output_type":"stream"},{"name":"stderr","text":"Train left Epoch 8:  67%|██████▋   | 10/15 [00:00<00:00, 43.16it/s]","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 21, 3)\n","output_type":"stream"},{"name":"stderr","text":"Val left Epoch 8:   0%|          | 0/5 [00:00<?, ?it/s]            ","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 21, 3)\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"[left] Epoch 8/10 | Train Loss: 2.5974 Acc: 0.2368 | Val Loss: 3.0968 Acc: 0.1448\n","output_type":"stream"},{"name":"stderr","text":"Train left Epoch 9:   0%|          | 0/15 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 21, 3)\n","output_type":"stream"},{"name":"stderr","text":"Val left Epoch 9:   0%|          | 0/5 [00:00<?, ?it/s]           ","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 21, 3)\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"[left] Epoch 9/10 | Train Loss: 2.6038 Acc: 0.2281 | Val Loss: 3.0848 Acc: 0.1724\n","output_type":"stream"},{"name":"stderr","text":"Train left Epoch 10:   7%|▋         | 1/15 [00:00<00:02,  6.01it/s]","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 21, 3)\n","output_type":"stream"},{"name":"stderr","text":"Val left Epoch 10:   0%|          | 0/5 [00:00<?, ?it/s]           ","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 21, 3)\n","output_type":"stream"},{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"[left] Epoch 10/10 | Train Loss: 2.6018 Acc: 0.2412 | Val Loss: 3.4086 Acc: 0.1448\nDone left. Best val acc: 0.2069\n\n--- Pretraining right ---\nSố mẫu train: 456, val: 145\nSố batch train: 15, val: 5\nUsing DataParallel with 2 GPUs\n","output_type":"stream"},{"name":"stderr","text":"Train right Epoch 1:  60%|██████    | 9/15 [00:00<00:00, 37.21it/s]","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 21, 3)\n","output_type":"stream"},{"name":"stderr","text":"Val right Epoch 1:   0%|          | 0/5 [00:00<?, ?it/s]           ","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 21, 3)\n","output_type":"stream"},{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"[right] Epoch 1/10 | Train Loss: 3.9818 Acc: 0.0680 | Val Loss: 3.4868 Acc: 0.0207\nBest model saved at epoch 1, val_acc=0.0207\n","output_type":"stream"},{"name":"stderr","text":"Train right Epoch 2:   7%|▋         | 1/15 [00:00<00:02,  6.18it/s]","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 21, 3)\n","output_type":"stream"},{"name":"stderr","text":"Val right Epoch 2:   0%|          | 0/5 [00:00<?, ?it/s]           ","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 21, 3)\n","output_type":"stream"},{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"[right] Epoch 2/10 | Train Loss: 3.1762 Acc: 0.1338 | Val Loss: 3.8750 Acc: 0.0552\nBest model saved at epoch 2, val_acc=0.0552\n","output_type":"stream"},{"name":"stderr","text":"Train right Epoch 3:   0%|          | 0/15 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 21, 3)\n","output_type":"stream"},{"name":"stderr","text":"Val right Epoch 3:   0%|          | 0/5 [00:00<?, ?it/s]           ","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 21, 3)\n","output_type":"stream"},{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"[right] Epoch 3/10 | Train Loss: 2.8577 Acc: 0.1689 | Val Loss: 3.1885 Acc: 0.1172\nBest model saved at epoch 3, val_acc=0.1172\n","output_type":"stream"},{"name":"stderr","text":"Train right Epoch 4:   0%|          | 0/15 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 21, 3)\n","output_type":"stream"},{"name":"stderr","text":"Val right Epoch 4:   0%|          | 0/5 [00:00<?, ?it/s]           ","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 21, 3)\n","output_type":"stream"},{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"[right] Epoch 4/10 | Train Loss: 2.5788 Acc: 0.2697 | Val Loss: 2.7150 Acc: 0.2690\nBest model saved at epoch 4, val_acc=0.2690\n","output_type":"stream"},{"name":"stderr","text":"Train right Epoch 5:   7%|▋         | 1/15 [00:00<00:02,  6.10it/s]","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 21, 3)\n","output_type":"stream"},{"name":"stderr","text":"Val right Epoch 5:   0%|          | 0/5 [00:00<?, ?it/s]           ","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 21, 3)\n","output_type":"stream"},{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"[right] Epoch 5/10 | Train Loss: 2.4677 Acc: 0.2982 | Val Loss: 2.9977 Acc: 0.2897\nBest model saved at epoch 5, val_acc=0.2897\n","output_type":"stream"},{"name":"stderr","text":"Train right Epoch 6:   0%|          | 0/15 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 21, 3)\n","output_type":"stream"},{"name":"stderr","text":"Val right Epoch 6:   0%|          | 0/5 [00:00<?, ?it/s]           ","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 21, 3)\n","output_type":"stream"},{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"[right] Epoch 6/10 | Train Loss: 2.4150 Acc: 0.3158 | Val Loss: 2.8602 Acc: 0.2069\n","output_type":"stream"},{"name":"stderr","text":"Train right Epoch 7:   7%|▋         | 1/15 [00:00<00:02,  6.13it/s]","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 21, 3)\n","output_type":"stream"},{"name":"stderr","text":"Val right Epoch 7:   0%|          | 0/5 [00:00<?, ?it/s]           ","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 21, 3)\n","output_type":"stream"},{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"[right] Epoch 7/10 | Train Loss: 2.2081 Acc: 0.3465 | Val Loss: 2.6691 Acc: 0.2759\n","output_type":"stream"},{"name":"stderr","text":"Train right Epoch 8:   0%|          | 0/15 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 21, 3)\n","output_type":"stream"},{"name":"stderr","text":"Val right Epoch 8:   0%|          | 0/5 [00:00<?, ?it/s]            ","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 21, 3)\n","output_type":"stream"},{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"[right] Epoch 8/10 | Train Loss: 2.1461 Acc: 0.3816 | Val Loss: 2.6703 Acc: 0.3310\nBest model saved at epoch 8, val_acc=0.3310\n","output_type":"stream"},{"name":"stderr","text":"Train right Epoch 9:   0%|          | 0/15 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 21, 3)\n","output_type":"stream"},{"name":"stderr","text":"Val right Epoch 9:   0%|          | 0/5 [00:00<?, ?it/s]           ","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 21, 3)\n","output_type":"stream"},{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"[right] Epoch 9/10 | Train Loss: 2.0526 Acc: 0.4276 | Val Loss: 2.9096 Acc: 0.2966\n","output_type":"stream"},{"name":"stderr","text":"Train right Epoch 10:   0%|          | 0/15 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 21, 3)\n","output_type":"stream"},{"name":"stderr","text":"Val right Epoch 10:   0%|          | 0/5 [00:00<?, ?it/s]            ","output_type":"stream"},{"name":"stdout","text":"Dataset part_kp.shape: (64, 21, 3)\n","output_type":"stream"},{"name":"stderr","text":"                                                                 ","output_type":"stream"},{"name":"stdout","text":"[right] Epoch 10/10 | Train Loss: 2.1560 Acc: 0.3838 | Val Loss: 2.7161 Acc: 0.3172\nDone right. Best val acc: 0.3310\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"# 3. WLASL Module","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}